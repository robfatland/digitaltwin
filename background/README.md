A 'digital twin' is a buzz phrase meaning a system that uses physical sensor
devices to provide data to a virtual environment, and potentially vice versa. 
The digital twin idea is ascendant on the hype
curve at the moment; and I see it as a step on the technology evolution ladder 
of the general idea of *in situ* remote sensing. I will take a moment to describe 
some of my experience of this subject.


The early 2000s saw a rise in the advent of wireless sensor networks (WSNs).
The example projects I am aware of originated as research in academia. 
(I have no experience with military or industrial development since those 
domains tend to avoid the 'open'
paradigm.) WSNs had the advantage of being novel and interesting and they
occupied a perfect ***brave new world*** niche by bridging from computer
science into domain sciences like ecology and geophysics. However the early
phase of WSN development suffered from extremely intensive effort required
to make things work (often poorly). The reason for this is that the technology 
was adopted from commercial sources and was not yet, in a word, reliable. 
There were problems to solve concerning wireless communication, concerning
timestamping and geolocation via GPS, power management, ruggedization, and
sensor interfacing, usually in the context of microcontrollers and 
Linux workstations. The most successful 
research project that I had direct experience with was called Life Under Your Feet.
This was a soil ecology sensor network project based at Johns Hopkins. 


Simultaneously cloud computing arrived; 
and this became an obvious destination for data collected by a sensor network
provided there was a feasible telecommunications path available. 
This gave us the buzz phrase Internet of Things (IOT) which is still
very much in common use. 


Also in this geological time frame we had a revolution in DIY or hobbyist or
'Maker' culture that created demand for small, cheap computers,
particularly the Arduino and the Raspberry Pi. The Raspberry Pi runs Linux 
and began as a small workstation costing around USD30. It has no progressed
to its fourth generation and -- with increasing capabilities -- now seems 
to run a factor of 10 more expensive. The Arduino has also gone through
generations (now generation 3) but still sells for around USD30. 


A further note on Maker culture: The profusion of open projects has
propelled an explosion of peripheral devices in addition to cheap computers. 
These peripherals include range sensors,
cameras, accelerometers, display screens, temperature and light sensors, 
music players, power relays and access to a variety of telecommunications
protocols just to begin with. With the advent of GitHub and Stack Overflow 
and YouTube we have an access to content, how to 'go and do likewise'
and where to go 'cry out for help' respectively. This has drastically
lowered the barrier to entry to the brave new world of IoT. 


In the early 2010s this progression led to an expanded notion of what
automated systems could do in the real world beyond the server closet.
Devices that could actuate events, that could cause things to happen 
came into focus with the accompanying buzz phrase Cyber-Physical Systems (CPS),
with drones and and autonomous vehicles being the predominant poster children.


We have come through about two decades 
of rapid miniaturization, ruggedization and refinement of computing 
tools that operate in the physical world, now
routinely crawling and flying across the surface of mars. 


Digital twin has an interesting relationship to AI... 

A 'digital twin' uses physical sensors
to provide data to a virtual environment, and potentially vice versa. 
This idea is a step on the technology ladder 
for *in situ* remote sensing. I take a moment here to describe 
some of my experiences with this subject.


The early 2000s saw a rise in the advent of wireless sensor networks (WSNs).
The example projects I am aware of originated as research in academia. 
I have no experience with military or industrial developments since those 
domains tend to avoid the open
paradigm. WSNs built on 'embedded technology' were novel 
and interesting; they
occupied a perfect ***brave new world*** niche bridging computer
science to domain sciences like ecology and geophysics. However the early
phase of WSN development was fraught with peril. Progress depended on intensive 
effort required to cope with technology limitations. One could make things 
work eventually; but often just poorly. 
There were problems to solve concerning wireless communication, 
timestamping, geolocation via GPS, power management, ruggedization, and
sensor interfaces, usually in the context of microcontrollers and 
Linux workstations. The most successful 
project I had direct experience with was 'Life Under Your Feet', 
a soil ecology sensor network project based out of 
Johns Hopkins University. 


Simultaneous with this was the advent of cloud computing. 
The cloud became an obvious destination for data collected by a 
sensor network deployed in the field somewhere
provided there was a feasible telecommunications path available. 
This notion of devices reporting in to a central system became
known as the Internet of Things (IOT), a term still very much in use. 


Also simultaneous (early 2000s) we had the development of the Arduino
platform. This matured into a mass-production stage by around 2010 
and helped launch a DIY-powered explosion of digital devices, corresponding
to the advent of
'Maker' culture. This created demand for small, cheap sensors 
and other peripheral devices that can be interfaced to
these small, cheap computers. Arduino was and is arguably towards the low end 
of the computing power spectrum, where the high end would include devices like the 
Raspberry Pi. The latter runs Linux 
and is effectively a small workstation. It originally cost around USD30; but
now in its fourth generation runs a factor of 10 more. 
The Arduino has also gone through generations of revision (now on generation 3) 
but still sells for around USD30. 



The peripheral devices mentioned above include range sensors,
cameras, accelerometers, display screens, temperature and light sensors, 
music players, power relays and a variety of telecommunications
hardware and corresponding protocols. 
With the advent of GitHub and Stack Overflow 
and YouTube we have access not only to devices but also to
a culture of how to go about making it work. This has drastically
lowered the barrier to entry to the world of IOT. 


In the early 2010s the expanded notion of what
automated systems could do included more actuation, 
i.e. going beyond passive data recording to initiating actions 
in the deployment environment; with an accompanying
new term 'Cyber-Physical Systems' (CPS). Here
programmable drones and autonomous (driverless) vehicles are
the predominant CPS examples.


At this point we are sort of 'two decades in' to this
progression of miniaturization, ruggedization and 
expertise sharing. It is not dead simple yet, but 
we can take advantage of both the cellular network 
and satellite modems to get data back from out there
for a non-exhorbitant fee. Power is still a 
long-deployment challenge but the bottom line is that
we are in an era where we no longer need to devote 
five years in the lab with a soldering iron to 
realize some of our aspirations in sensing and
understanding what's going on out there.
